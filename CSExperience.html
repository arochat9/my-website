<!DOCTYPE html>
<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Andrew Rochat - Computer Science Experience</title>
    <link rel="apple-touch-icon" sizes="180x180" href="favicons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicons/favicon-16x16.png">
    <link rel="manifest" href="favicons/site.webmanifest">
    <link rel="mask-icon" href="favicons/safari-pinned-tab.svg" color="#5bbad5">
    <link rel="shortcut icon" href="favicons/favicon.ico">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="msapplication-config" content="favicons/browserconfig.xml">
    <meta name="theme-color" content="#ffffff">
    <link href="https://fonts.googleapis.com/css?family=Roboto:300" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <link href="css/JaneStreetStyle.css" rel="stylesheet">
  </head>
  <body>
    <div class="header-wrapper">
      <header style="background-image: url(images/header4.png); background-position: 50% 65%"></header>
    </div>
    <h1>Computer Science Experience</h1>
    <section>
      <div class="image right" style="background-image: url(images/axegine200by200.png);"></div>
      <div class="content">
        <h2>Software Engineer at Axegine Capital Management LLC</h2>
        <p>
          At Axegine, an investment bank venture, I worked side by side with bond traders to build a web page that showcased graphical data representations of the market, leading to a more streamlined process for traders to access their analytics. I also built front end data visualization tools for the local development environment that Axegine uses for back testing different bond trading market strategies. Finally, I created a login security page using an LDAP protocol for automatically authenticating users based on Axegine's active directory. I was also responsible for creating varying access levels for different security groups.
        </p>
      </div>
    </section>
    <section>
      <div class="image right" style="background-image: url(images/hungryjacks.png);"></div>
      <div class="content">
        <h2>Data Analytics Intern for Hungry Jack's Australia</h2>
        <p>
          At Hungry Jack's, I used Python to create a historical weather database, and subsequently developed a Tableau dashboard that blended weather data with Hungry Jack's sales data. Furthermore, I aggregated school and public holiday information and created a presentation that showed sales growth by holiday, store, and product. Next, we used this information for targeted marketing campaigns, as well as variably increasing staff to match historical sales percentage increases.
        </p>
      </div>
    </section>
    <section>
      <div class="image right" style="background-image: url(images/teachingassistant.jpg); border: none"></div>
      <div class="content">
        <h2>Head Teaching Assistant at Washington University in St. Louis</h2>
        <p>
          At WashU, I was employed as the head teaching assistant for CSE450 Videogame Programming where I used my technical expertise to aid students with topics including graphics, artificial intelligence, user interface design, and networking. Furthermore, I collaborated with professors and a dedicated team of fellow teaching assistants to create an effective and efficient learning environment by holding weekly office hours and grading assignments.
        </p>
      </div>
    </section>
    <section>
      <div class="image right" style="background-image: url(images/selenium460by460.jpg);"></div>
      <div class="content">
        <h2>Climate Data Preservation Research Project Member	Employee</h2>
        <p>
          For this project, our team was tasked with building an advanced web crawler to collect climate and other environmental data from federal government websites to ensure that it remains publicly available for research, advocacy, and citizen enforcement. To achieve this, we built selenium web scraper using Python that archived several thousand government dockets and scientific data centered around disposal of coal combustion residuals from electric utilities. Next, we upgraded and expanded the web crawler’s versatility to work for a variety of government dockets such as standards for greenhouse gas emissions from various sources.
        </p>
      </div>
    </section>
    <footer></footer>
  </body>
</html>

<!DOCTYPE html>
<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Andrew Rochat - Computer Science Experience</title>
    <link rel="apple-touch-icon" sizes="180x180" href="favicons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicons/favicon-16x16.png">
    <link rel="manifest" href="favicons/site.webmanifest">
    <link rel="mask-icon" href="favicons/safari-pinned-tab.svg" color="#5bbad5">
    <link rel="shortcut icon" href="favicons/favicon.ico">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="msapplication-config" content="favicons/browserconfig.xml">
    <meta name="theme-color" content="#ffffff">
    <link href="https://fonts.googleapis.com/css?family=Roboto:300" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <link href="css/JaneStreetStyle.css" rel="stylesheet">
  </head>
  <body>
    <div class="header-wrapper">
      <header style="background-image: url(images/header4.png); background-position: 50% 65%"></header>
    </div>
    <h1>Computer Science Experience</h1>
    <section>
      <div class="image right" style="background-image: url(images/axegine200by200.png);"></div>
      <div class="content">
        <h2>Software Engineer at Axegine Capital Management LLC</h2>
        <p>
          As a software engineering intern at Axegine Capital Management, an algorithmic trading venture, I worked in C++ and Python on their market analytics dashboard.  A large part of my job was adapting and refactoring legacy source code from their codebase.  For the market dashboard, I used Plotly's Dash framework to build front-end data visualization tools.  I also created a multithreaded platform for traders to upload and back test different automated trading strategies asynchronously.  Finally, I created a login security system using an LDAP protocol for automatically authenticating users based on Axegine's active directory.
        </p>
      </div>
    </section>
    <section>
      <div class="image right" style="background-image: url(images/hungryjacks.png);"></div>
      <div class="content">
        <h2>Data Science Intern for Hungry Jack's Australia</h2>
        <p>
          At Hungry Jack's, I used Python to create a historical weather database, and subsequently developed a Tableau dashboard that blended weather data with Hungry Jack's sales data. Furthermore, I aggregated school and public holiday information and created a presentation that showed sales growth by holiday, store, and product. Next, we used this information for targeted marketing campaigns, as well as variably increasing staff to match historical sales percentage increases.
        </p>
      </div>
    </section>
    <section>
      <div class="image right" style="background-image: url(images/teachingassistant.jpg); border: none"></div>
      <div class="content">
        <h2>Head Teaching Assistant at Washington University in St. Louis</h2>
        <p>
          At WashU, I worked as a teaching assistant for CSE330 Rapid Prototype Development where I used my technical expertise to aid students with topics such as building a Linux web server in Apache, creating websites using PHP, JavaScript, HTML, and CSS, and creating databases using MySQL.  I also taught more complex topics such as .NET architecture, and JavaScript frameworks like React, XML, and Node.JS.  As a teaching assistant, I also collaborated with professors and fellow TA's to create an effective and efficient learning environment by holding weekly office hours and grading assignments.
        </p>
      </div>
    </section>
    <section>
      <div class="image right" style="background-image: url(images/selenium460by460.jpg);"></div>
      <div class="content">
        <h2>Climate Data Preservation Research Project Member	Employee</h2>
        <p>
          For this project, our team was tasked with building an advanced web crawler to collect climate and other environmental data from federal government websites to ensure that it remains publicly available for research, advocacy, and citizen enforcement. To achieve this, we built selenium web scraper using Python that archived several thousand government dockets and scientific data centered around disposal of coal combustion residuals from electric utilities. Next, we upgraded and expanded the web crawlerâ€™s versatility to work for a variety of government dockets such as standards for greenhouse gas emissions from various sources.
        </p>
      </div>
    </section>
    <footer></footer>
  </body>
</html>
